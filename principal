import json
from bs4 import BeautifulSoup
import pandas as pd
import requests
import numpy as np
import datetime
from datetime import date
import urllib.request
from html_table_parser.parser import HTMLTableParser
import mibian
import urllib3
import funciones_web_scrap

url = 'https://www.meff.es/esp/Derivados-Financieros/Ficha/FIEM_MiniIbex_35'
web_content = pd.read_html(url,thousands='.', decimal=',')
futuros = web_content[0]
datos_futuro = futuros.iloc[:,[0,futuros.shape[1]-1]]
datos_futuro = datos_futuro.iloc[0,:]


response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
dias = soup.find('select', attrs={'class': 'form-control', 'id': 'OpStrike'})
dias_opciones = []
for i in range(0,len(dias.text),10):
    dias_opciones.append(dias.text[i:i+10])
dias_opc = pd.unique(dias_opciones[0:len(dias_opciones)-2])

# defining the html contents of a URL.
xhtml = url_get_contents('https://www.meff.es/esp/Derivados-Financieros/Ficha/FIEM_MiniIbex_35').decode('utf-8')

# Defining the HTMLTableParser object
p = HTMLTableParser()

# feeding the html contents in the
# HTMLTableParser object
p.feed(xhtml)

u = p.tables[1][2:len(p.tables[1])]
u = u[0:len(u)-2]
# Para volverlos float
for i in range(len(u)):
    for j in range(len(u[i])):
        if type(u[i][j]) != float and u[i][j] != "-" :
            u[i][j] = u[i][j].replace(".", "")
            u[i][j] = u[i][j].replace(",", ".")
            u[i][j] = float(u[i][j])      

headers = ['Strike',
'Ord.',
'Vol.',
'Precio',
'Precio',
'Vol.',
'Ord.',
'Últ.',
'Vol.',
'Aper.',
'Máx.',
'Min.',
'Ant.']
precios_opc = pd.DataFrame(u,columns = headers)
precios_dias = filtro_opc_por_dias (precios_opc, dias_opc)
datos_completos = get_call_put_data (precios_dias)
print(datos_completos)